{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37d8457-bb65-4f83-93d4-15421921aac0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# GND/Getty Semi-Auto Updater\n",
    "\n",
    "UNIDAM instance of Easydb5 at the University of Vienna\n",
    "\n",
    "Trying to automate `Kuenstler` objecttype insertion of GND entries\n",
    "\n",
    "Author: Janos Bekesi (janos.bekesi@univie.ac.at)\n",
    "\n",
    "## Preconditions\n",
    "\n",
    "Some grasp of `python` and [pandas](https://pandas.pydata.org/) is needed for anyone using this notebook, since some small code changes will probably be necessary.\n",
    "\n",
    "Also beforehand, the `easydb` datamodel has to be changed accordingly to host GND, Getty and Wikidata entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63262817-f254-44bd-895e-023f77262cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from zipfile import ZipFile\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "# external libraries:\n",
    "# they should be installed by `pip` or `conda` in the notebook environment (e.g. jupyterhub)\n",
    "import pandas as pd\n",
    "import request\n",
    "import duckdb\n",
    "import tqdm\n",
    "\n",
    "datadir = Path(\"./data-unidam\")\n",
    "pprint(sorted(datadir.iterdir())[:10])\n",
    "\n",
    "# inserting data from excel file (taxons acceptet etc)\n",
    "def to_csv(df, csvname, headers=None):\n",
    "    if headers:\n",
    "        df.loc[-2] = headers\n",
    "    df.index = df.index + 1  # shifting index\n",
    "    df = df.sort_index()  # sorting by index \n",
    "    df.to_csv(datadir.joinpath(\"{}.csv\".format(csvname)), quoting=2, sep=\";\", index=False)  \n",
    "    \n",
    "def curtime(long=False):\n",
    "    now = datetime.datetime.now()\n",
    "    if long:\n",
    "        generated_at = now.isoformat()\n",
    "        generated_at = generated_at.split(\".\")[0] #  . + '}\"\"'\n",
    "        return long\n",
    "    return now.strftime(\"%Y%m%d_%H%M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21d8229-dd45-46bc-80d1-7c882f3fcf37",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Create a `pandas` dataset from an CSV export of all `kuenstler` objects\n",
    "\n",
    "The datafile has to be in `datadir` (which could be adopted to respective needs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d628d8bf-e8c8-4555-bc97-2ff143363e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13926 rows\n"
     ]
    }
   ],
   "source": [
    "datafile = \"unidam_kuenstler.zip\"\n",
    "with ZipFile(str(datadir.joinpath(datafile) )) as zf:\n",
    "    for fn in zf.namelist():\n",
    "        if fn.endswith(\".csv\"):\n",
    "            with zf.open(fn) as csvr:\n",
    "                df = pd.read_csv(csvr, sep=\";\")\n",
    "\n",
    "print(f\"{df.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32668268-6890-4ce1-b099-baddcab25634",
   "metadata": {},
   "source": [
    "## GND search function definition\n",
    "\n",
    "Wikidata entries are retained, too\n",
    "\n",
    "queries GND via `lobid.org` (cf. easydb custom data type `gnd`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f0fbbc7b-1870-486c-8be3-507e2eccc5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_gnd(\n",
    "    person_name,\n",
    "    upper_limit=100,\n",
    "    restrict_by_birthyear=False,\n",
    "    write_rdf=False,\n",
    "    write_csv=False,\n",
    "    birthyear_max=1970,\n",
    "    lebensdaten=\"\",\n",
    "    verbose=False,\n",
    "    ):\n",
    "    lobid = \"https://lobid.org/gnd/search\"\n",
    "    pn = \"preferredName:{}\"\n",
    "    params = {\"filter\": \"type:Person\", \"format\": \"json\"}\n",
    "    uris = []\n",
    "    no_rec = 0\n",
    "    params[\"q\"] = pn.format(person_name)\n",
    "    r = requests.get(lobid, params=params)\n",
    "    if r.status_code != 200:\n",
    "        print(r.status_code, \"status\")\n",
    "        return 0\n",
    "    data = r.json()\n",
    "    items = int(data[\"totalItems\"])\n",
    "    if int(items) == 0:\n",
    "        if verbose:\n",
    "            print(f\"   nothing found in GND for {person_name}\")  #  = no bindings\n",
    "    elif items > upper_limit:\n",
    "        print(\n",
    "            f\"{items} are more than {upper_limit} GND entries ({no_rec}) found for {person_name}\"\n",
    "        )  #  = no bindings\n",
    "        return items\n",
    "    for m in data.get(\"member\", []):\n",
    "        date_birth = m.get(\"dateOfBirth\", None)\n",
    "        date_death = m.get(\"dateOfDeath\", None)\n",
    "        pref_name = m.get(\"preferredName\")\n",
    "        if not pref_name == person_name:\n",
    "            continue\n",
    "        gnd_id = m.get(\"gndIdentifier\")\n",
    "        gnd_url = m.get(\"id\")\n",
    "        sameas = m.get(\"sameAs\", [])\n",
    "        wiki_id = \"\"\n",
    "        if verbose:\n",
    "            print(gnd_url, gnd_id, pref_name, date_birth, date_death)\n",
    "        try:\n",
    "            if not date_birth:\n",
    "                dob = \"0\"\n",
    "            else:\n",
    "                if isinstance(date_birth, list):\n",
    "                    date_birth = date_birth[0]\n",
    "                dob = (\n",
    "                    date_birth\n",
    "                    if date_birth.find(\"-\") == -1\n",
    "                    else date_birth.split(\"-\")[0]\n",
    "                )\n",
    "            dob = int(dob)\n",
    "        except ValueError:\n",
    "            dob = 0\n",
    "        if restrict_by_birthyear and dob > birthyear_max:\n",
    "            continue\n",
    "        if lebensdaten: #  try to confirm:\n",
    "            if lebensdaten.find(str(dob)) < 0:\n",
    "                continue\n",
    "        for sa in sameas:\n",
    "            coll = sa.get(\"collection\", {})\n",
    "            # print(\"-\" * 40)\n",
    "            if coll.get(\"abbr\", \"\") == \"WIKIDATA\":\n",
    "                wiki_id = sa.get(\"id\", \"\")\n",
    "                # print(\"  wikidata:\", wiki_id)\n",
    "                break\n",
    "        uris.append((pref_name, dob, gnd_url, wiki_id))\n",
    "    if write_csv:\n",
    "        uris = [(\"dateofbirth\", \"uri\", \"wiki_uri\")] + uris\n",
    "        with open(filename.with_suffix(\".csv\"), \"w\") as urifile:\n",
    "            csvw = csv.writer(urifile)\n",
    "            csvw.writerows(uris)\n",
    "    else:\n",
    "        return uris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222b08c-9971-47e3-9348-e10915f2e7e6",
   "metadata": {},
   "source": [
    "## Getty search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5115624-f909-4e9c-a6fc-3b2d7f2e1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def query_getty(search_name, bio, voc=\"ulan\", max_result=4, verbose=True):\n",
    "    \"\"\"\n",
    "    https://ws.gbv.de/suggest/getty/?searchstring=' + getty_searchterm + '&voc=' + \n",
    "    getty_searchtype + '&count=' + getty_countSuggestion\"\n",
    "    \n",
    "    \"\"\"\n",
    "    getty_url = \"https://ws.gbv.de/suggest/getty\"\n",
    "    params = {\"searchstring\": \"\", \"count\": max_result, \"voc\": voc}\n",
    "    perscon = \"PersonConcept\"\n",
    "    uris = []\n",
    "    no_rec = 0\n",
    "    # prepare search_name:\n",
    "    if search_name.find(\",\") > -1:\n",
    "        snl = search_name.split(\",\")\n",
    "        snl.reverse()\n",
    "        snl = [x.strip() for x in snl]\n",
    "        search_name = \" \".join(snl)\n",
    "        search_name = search_name.lower()\n",
    "    params[\"searchstring\"] = search_name\n",
    "    r = requests.get(getty_url, params=params)\n",
    "    if r.status_code != 200:\n",
    "        print(r.status_code, \"status\")\n",
    "        return 0\n",
    "    data = r.json()\n",
    "    if verbose: \n",
    "        print(data)\n",
    "    query, names, concepts, urls = data\n",
    "    if not len(names):\n",
    "        return [[]]\n",
    "    if len(names) == 1:\n",
    "        if concepts[0].find(perscon) > -1:\n",
    "            return [[(names[0], urls[0])]]\n",
    "    else:\n",
    "        for idx, concept in enumerate(concepts):\n",
    "            if concept.find(perscon) > -1:\n",
    "                uris.append([names[idx], urls[idx]])\n",
    "    return uris\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7ef06-0345-4420-99db-a45df8ac6eca",
   "metadata": {},
   "source": [
    "## Function for rendering easydb link javascript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "730dd333-5be3-4227-a725-b92e8d24c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def mk_link(url, name, linktype=\"gnd\"):\n",
    "    if not url:\n",
    "        return url\n",
    "    url = url.replace(\"http:\", \"https:\")\n",
    "    if linktype in (\"gnd\", \"getty)\":\n",
    "        urldict = {\"conceptURI\": url,\n",
    "              \"conceptName\": name}\n",
    "        return json.dumps(urldict)\n",
    "    elif linktype == 'wd':\n",
    "        urldict = {'url': url, 'title': name}\n",
    "        return json.dumps(urldict)\n",
    "    return url    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903958dc-6575-4e66-bdd5-f332462e8e55",
   "metadata": {},
   "source": [
    "## CSV output\n",
    "\n",
    "Run for all `Kuenstler` on prod (2023-03-28):\n",
    "\n",
    "```\n",
    "not found: 7390\n",
    "Multiples: 803\n",
    "Unique: 5567\n",
    "Too many: 166\n",
    "found 6536, not found 7390\n",
    "found 47 % GND entries of 13926 items\n",
    "CPU times: user 2min 9s, sys: 6.94 s, total: 2min 16s\n",
    "Wall time: 26min 51s\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57467bd3-8ed6-43d6-a1dd-93708075841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#\n",
    "# 1000 items are processed in 120 secs / 2 mins\n",
    "#\n",
    "\n",
    "out = []\n",
    "total = df.shape[0]\n",
    "test = total-1\n",
    "cnt = 0\n",
    "not_found = []\n",
    "multiples = []\n",
    "too_many = []\n",
    "df.fillna(\"\", inplace=True)\n",
    "for row in df.itertuples():\n",
    "    system_object_id = row._4\n",
    "    ld = row.lebensdaten\n",
    "    search = row.name\n",
    "    gnd = query_gnd(search, lebensdaten=ld)\n",
    "    if not gnd:\n",
    "        not_found.append((search, system_object_id))\n",
    "    else:\n",
    "        if isinstance(gnd, int):\n",
    "            too_many.append((search, system_object_id, gnd))\n",
    "            continue\n",
    "        if len(gnd) > 1:\n",
    "            multiples.append((search, system_object_id, gnd))\n",
    "        else:\n",
    "            out.append((search, system_object_id, gnd))\n",
    "    cnt += 1\n",
    "    if cnt > test:\n",
    "        break\n",
    "print(f\"not found: {len(not_found)}\")\n",
    "# pprint(not_found)\n",
    "print(f\"Multiples: {len(multiples)}\")\n",
    "# pprint(multiples)\n",
    "print(f\"Unique: {len(out)}\")\n",
    "# pprint(out)\n",
    "print(f\"Too many: {len(too_many)}\")\n",
    "print(f\"found {len(out)+len(multiples) + len(too_many)}, not found {len(not_found)}\")\n",
    "print(\"found {} % GND entries of {} items\".format(\n",
    "    round((len(out) + len(multiples) + len(too_many)) * 100 / (total)),\n",
    "    total))\n",
    "\n",
    "data = []\n",
    "\n",
    "# easydb5 fieldnames according to the kuenstler object in the datamodel:\n",
    "ez5cols = [\"_system_object_id\", \n",
    "           \"gnd\",\n",
    "           \"gnd_pruefen\", \n",
    "           \"wikidata\", \n",
    "           \"gnd_pruefdaten[].gnd_pruefeintrag\"]\n",
    "\n",
    "for name, sysid, gnd_row in out:\n",
    "    gnd = gnd_row[0]\n",
    "    gnd_url = gnd[2]\n",
    "    gnd_link = mk_link(gnd_url, gnd[0])\n",
    "    wiki_url = gnd[3]\n",
    "    wiki_link = \"\"\n",
    "    if wiki_url:\n",
    "        wiki_link = mk_link(wiki_url, gnd[0], linktype=\"wd\")\n",
    "    tmp = [sysid, gnd_link, 0, wiki_link, \"\"]\n",
    "    data.append(tmp)\n",
    "for name, sysid, gnd_many in too_many:\n",
    "    data.append([sysid, \"\", 1, \"\", \"\"])\n",
    "    \n",
    "for name, sysid, gnd_rows in multiples:\n",
    "    pruef = []\n",
    "    for gr in gnd_rows:\n",
    "        name, birth_year, gnd_url, wd = gr\n",
    "        pruef.append(mk_link(gnd_url, name))\n",
    "    tmp = [\n",
    "        sysid,\n",
    "        \"\", 1, \"\", \"\\n\".join(pruef)\n",
    "        \n",
    "    ]\n",
    "    data.append(tmp)\n",
    "curt = curtime()\n",
    "df_gnd = pd.DataFrame(data)\n",
    "to_csv(df_gnd, f\"gnd_kuenstler_{total}_{curt}\", headers=ez5cols)\n",
    "print(\"use gnd_kuenstler_* csv for importing into csv importer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e9106e-1cf5-47a4-b2bf-de3c90e85f85",
   "metadata": {},
   "source": [
    "## Try out `duckdb` for SQL speed\n",
    "\n",
    "([duckdb](https://duckdb.org/) offers an easy and fast way to query datasets by SQL)\n",
    "\n",
    "And look up Getty information...\n",
    "\n",
    "```\n",
    "Took 5h 11min on 2023-03-29\n",
    "6868 unique entries found \n",
    "1675 multiple entries\n",
    "of 13926 objects\n",
    "````\n",
    "\n",
    "61% of all entries found.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "71eff06c-22c1-47d2-9824-648f38619555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12476-619740@0678eb41-c907-4f71-a4a1-b9ec119d9652.csv\n",
      "13926 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032a0396bc3e4aa1959f6e6e13f56b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12476, 'Exekias', '')\n",
      "CPU times: user 400 ms, sys: 102 ms, total: 502 ms\n",
      "Wall time: 2.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import notebook, tnrange\n",
    "\n",
    "first = True #. only show first row\n",
    "multiples = []\n",
    "not_found = []\n",
    "singles = []\n",
    "datafile = \"unidam_kuenstler.zip\"\n",
    "data_csv = fn =  \"12476-619740@0678eb41-c907-4f71-a4a1-b9ec119d9652.csv\"\n",
    "if first:\n",
    "    with ZipFile(str(datadir.joinpath(datafile) )) as zf:\n",
    "        for fn in zf.namelist():\n",
    "            if fn.endswith(\".csv\"):\n",
    "                print(fn)\n",
    "                zf.extract(fn)\n",
    "                break\n",
    "#lookup = duckdb.sql(f\"SELECT _system_object_id, name, \" \n",
    "#                    f\"lebensdaten FROM '{fn}' where lebensdaten <> '' \").fetchall()\n",
    "lookup = duckdb.sql(f\"SELECT _system_object_id, name, \" \n",
    "                    f\"lebensdaten FROM '{fn}'\").fetchall()\n",
    "\n",
    "print(len(lookup), \"rows\")\n",
    "total = len(lookup)\n",
    "pbar = notebook.tqdm(total=total)\n",
    "for row in lookup:\n",
    "    if first: \n",
    "        print(row)\n",
    "        break\n",
    "    sysid, name, bio = row\n",
    "    if name.find(\",\") == -1:\n",
    "        nl = name.rsplit(\" \", maxsplit=1)\n",
    "        nl.reverse()\n",
    "        name = \", \".join(nl)\n",
    "    res = query_getty(name, bio, verbose=False)\n",
    "    pbar.update()\n",
    "    if res in ([], [[]]):\n",
    "        not_found.append((sysid, name))\n",
    "        continue\n",
    "    if len(res) == 1:\n",
    "        singles.append((sysid, mk_link(res[0][1], res[0][0])))\n",
    "    else:\n",
    "        tmp = []\n",
    "        for resrow in res:\n",
    "            tmp.append(mk_link(resrow[1], resrow[0]))\n",
    "        multiples.append((sysid, \"\\n\".join(tmp)))\n",
    "if not first:\n",
    "    cur = curtime()\n",
    "    ez5cols = [\"_system_object_id\", \"getty\"]\n",
    "    dfgt = pd.DataFrame(singles)\n",
    "    to_csv(dfgt, f\"getty_kuenstler_{len(singles)}_{curt}\", headers=ez5cols)\n",
    "    print(f\"found {len(singles)} single items\")\n",
    "    print(f\"found {len(multiples)} multiple_items\")\n",
    "    print(f\"not found {len(not_found)} items of {len(lookup)}\")\n",
    "    dfgtmu = pd.DataFrame(multiples)\n",
    "    to_csv(dfgtmu, f\"getty_multi_kue_{len(multiples)}_{cur}\", headers=[\"_system_object_id\", \"getty_multiples\"])\n",
    "    percentage = (len(singles) + len(multiples)) * 100 / total\n",
    "    print(\"found {} % Getty entries of {} items\".format(\n",
    "        round(percentage),\n",
    "        total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc7eab6-f4cd-4b00-92e2-a5bcf7f38509",
   "metadata": {},
   "source": [
    "## Toggle `automated` switch\n",
    "\n",
    "This was forgotten further above, so the field `gnd_getty_auto` is switched to ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "26a9d508-69ef-40a1-ba27-1baf81b3ce4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = curtime()\n",
    "headers = [\"_system_object_id\", \"gnd_getty_auto\"]\n",
    "for g in (\"gnd\", \"getty\"):\n",
    "    # select is strange, because columns start with 0,1 as headers in prev. output\n",
    "    fn = datadir.joinpath(\"gnd_kuenstler_15000_20230328_0938.csv\")\n",
    "    lookup = duckdb.sql(f\"SELECT COLUMNS('0') as '_system_object_id', 1 as 'gnd_getty_auto' FROM '{fn}' OFFSET 1\")# .fetchall()\n",
    "    lookup.write_csv(str(datadir.joinpath(f\"autoswitch_upd_{g}_{cur}.csv\")), sep=\";\", header=True)\n",
    "print(\"done, use autoswitch_upd_* csv files to update easydb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
